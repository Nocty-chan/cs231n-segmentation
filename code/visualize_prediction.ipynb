{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2 \n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from train import Trainer\n",
    "from generator import *\n",
    "from discriminator import GAN\n",
    "from dataset import CocoStuffDataSet\n",
    "import os, argparse, datetime, json\n",
    "\n",
    "from utils import *\n",
    "NUM_CLASSES = 11\n",
    "SAVE_DIR = \"../checkpoints\" # Assuming this is launched from code/ subfolder.\n",
    "experiment_name = 'baseline'\n",
    "gan_name = 'gan_low_reg'\n",
    "\n",
    "use_bn = True\n",
    "experiment_dir = os.path.join(SAVE_DIR, experiment_name)\n",
    "gan_dir = os.path.join(SAVE_DIR, gan_name)\n",
    "batch_size = 64\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT, WIDTH = 128, 128\n",
    "val_loader = DataLoader(CocoStuffDataSet(mode='val', supercategories=['animal'], height=HEIGHT, width=WIDTH),\n",
    "                            batch_size, shuffle=False)\n",
    "train_loader = DataLoader(CocoStuffDataSet(mode='train', supercategories=['animal'], height=HEIGHT, width=WIDTH),\n",
    "                            batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = SegNet16(NUM_CLASSES, use_bn=use_bn)\n",
    "gan_generator = SegNet16(NUM_CLASSES, use_bn=use_bn)\n",
    "image_shape = (3, HEIGHT, WIDTH)\n",
    "segmentation_shape = (NUM_CLASSES, HEIGHT, WIDTH)\n",
    "discriminator = None\n",
    "trainer = Trainer(generator, discriminator, train_loader, val_loader, \\\n",
    "                 experiment_dir=experiment_dir, resume=True, load_iter=None)\n",
    "gan_trainer = Trainer(gan_generator, discriminator, train_loader, val_loader, \\\n",
    "                 experiment_dir=gan_dir, resume=True, load_iter=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_mask(trainer, loader, number, save=False, gan_trainer=None):\n",
    "    total = 0\n",
    "    to_return = []\n",
    "    for data, mask_gt, gt_visual in loader:\n",
    "        if total < number: \n",
    "            data = data.cuda()\n",
    "            batch_size = data.size()[0]\n",
    "            mask_pred = convert_to_mask(trainer._gen(data))\n",
    "            if gan_trainer is not None:\n",
    "                gan_pred = convert_to_mask(gan_trainer._gen(data))\n",
    "            for i in range(len(data)):\n",
    "                img = data[i].detach().cpu().numpy()\n",
    "                gt_mask = gt_visual[i].detach().cpu().numpy()\n",
    "                pred_mask = np.argmax(mask_pred[i].detach().cpu().numpy(), axis=0)\n",
    "                to_return.append((img, gt_mask, pred_mask))\n",
    "                display_image = np.transpose(img, (1, 2, 0))\n",
    "                plt.figure(figsize=(20, 20))\n",
    "\n",
    "                plt.subplot(141)\n",
    "                plt.imshow(display_image)\n",
    "                plt.axis('off')\n",
    "                plt.title('original image')\n",
    "\n",
    "                cmap = discrete_cmap(NUM_CLASSES, 'Paired')\n",
    "                norm = colors.NoNorm(vmin=0, vmax=NUM_CLASSES)\n",
    "\n",
    "                plt.subplot(142)\n",
    "                plt.imshow(display_image)\n",
    "                plt.imshow(gt_mask, alpha=0.8, cmap=cmap, norm=norm)\n",
    "                plt.axis('off')\n",
    "                plt.title('real mask')\n",
    "\n",
    "                plt.subplot(143)\n",
    "                plt.imshow(display_image)\n",
    "                plt.imshow(pred_mask, alpha=0.8, cmap=cmap, norm=norm)\n",
    "                plt.axis('off')\n",
    "                plt.title('predicted mask')\n",
    "                if gan_trainer is not None:\n",
    "                    gan_pred_mask = np.argmax(gan_pred[i].detach().cpu().numpy(), axis=0)\n",
    "                    plt.subplot(144)\n",
    "                    plt.imshow(display_image)\n",
    "                    plt.imshow(gan_pred_mask, alpha=0.8, cmap=cmap, norm=norm)\n",
    "                    plt.axis('off')\n",
    "                    plt.title('GAN predicted mask')\n",
    "                plt.show()\n",
    "                \n",
    "                ### Now save image and background masks for style transfer\n",
    "                if save:\n",
    "                    idx = i + total\n",
    "                    print (\"Image {}\".format(idx))\n",
    "                    savedir = os.path.join('./saved_images_and_masks', str(idx))\n",
    "                    if not os.path.exists(savedir):\n",
    "                        os.makedirs(savedir)\n",
    "                    gt_background = np.where(gt_mask == 10., 1, 0)\n",
    "                    pred_background = np.where(pred_mask == 10., 1, 0)\n",
    "                    torch.save(torch.from_numpy(img), os.path.join(savedir, 'img.pk'))\n",
    "                    torch.save(torch.from_numpy(gt_background), os.path.join(savedir, 'gt_mask.pk')) # only care about background class\n",
    "                    torch.save(torch.from_numpy(pred_background), os.path.join(savedir, 'baseline_mask.pk'))  # only care about background class\n",
    "                    if gan_trainer is not None:\n",
    "                        gan_background = np.where(gan_pred_mask == 10., 1, 0)\n",
    "                        torch.save(torch.from_numpy(gan_background), os.path.join(savedir, 'gan_mask.pk'))  # only care about background class\n",
    "#                     plt.imshow(gt_background)\n",
    "#                     plt.show()\n",
    "#                     plt.imshow(pred_background)\n",
    "#                     plt.show()\n",
    "            total += batch_size\n",
    "\n",
    "        else:\n",
    "            break\n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = visualize_mask(trainer, train_loader, 30, gan_trainer=gan_trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = visualize_mask(trainer, val_loader, 600, save=True, gan_trainer=gan_trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pixel_acc, val_mIOU, per_class_accuracy = trainer.evaluate(val_loader, 0, ignore_background=True)\n",
    "\n",
    "print (\"Pixel accuracy {}\".format(val_pixel_acc))\n",
    "print (\"Val mIOU {}\".format(val_mIOU))\n",
    "print (\"per_class_accuracy {}\".format(per_class_accuracy))\n",
    "\n",
    "val_pixel_acc, val_mIOU, per_class_accuracy = gan_trainer.evaluate(val_loader, 0, ignore_background=True)\n",
    "\n",
    "print (\"Pixel accuracy {}\".format(val_pixel_acc))\n",
    "print (\"Val mIOU {}\".format(val_mIOU))\n",
    "print (\"per_class_accuracy {}\".format(per_class_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pixel_acc, train_mIOU, per_class_accuracy = trainer.evaluate(train_loader, 0, ignore_background=True)\n",
    "\n",
    "print (\"Pixel accuracy {}\".format(train_pixel_acc))\n",
    "print (\"Val mIOU {}\".format(train_mIOU))\n",
    "print (\"per_class_accuracy {}\".format(per_class_accuracy))\n",
    "\n",
    "train_pixel_acc, val_mIOU, per_class_accuracy = gan_trainer.evaluate(train_loader, 0, ignore_background=True)\n",
    "\n",
    "print (\"Pixel accuracy {}\".format(train_pixel_acc))\n",
    "print (\"Val mIOU {}\".format(train_mIOU))\n",
    "print (\"per_class_accuracy {}\".format(per_class_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONFUSION MATRIX ##\n",
    "\n",
    "confusion_matrix = trainer.get_confusion_matrix(val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = val_loader.dataset\n",
    "coco = dataset.coco\n",
    "all_cats_ids = coco.getCatIds()\n",
    "cats = coco.loadCats(all_cats_ids)\n",
    "nms=[cat['name'] for cat in cats]\n",
    "\n",
    "animal_cat_names = [nms[all_cats_ids.index(i)] for i in val_loader.dataset.catIds] + ['background']\n",
    "print (animal_cat_names)\n",
    "visualize_conf(confusion_matrix, animal_cat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
