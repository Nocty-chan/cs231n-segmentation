{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from style_transfer import *\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import PIL\n",
    "import numpy as np\n",
    "from scipy.misc import imread\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import CocoStuffDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.60s)\n",
      "creating index...\n",
      "index created!\n",
      "Loaded 1016 samples: \n"
     ]
    }
   ],
   "source": [
    "dtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "\n",
    "HEIGHT = WIDTH = 256\n",
    "val_dataset = CocoStuffDataSet(mode='val', supercategories=['animal'], height=HEIGHT, width=WIDTH, do_normalize=False)\n",
    "# content_image, background_mask = get_image(val_dataset, args.content_index)\n",
    "content_image, background_mask = get_image(val_dataset, 417)\n",
    "foreground_mask = 1.0 - background_mask\n",
    "\n",
    "cnn = torchvision.models.vgg16(pretrained=True).features\n",
    "style_layers = (0, 5, 10, 17, 24)\n",
    "\n",
    "cnn.type(dtype)\n",
    "# We don't want to train the model any further, so we don't want PyTorch to waste computation \n",
    "# computing gradients on parameters we're never going to update.\n",
    "for param in cnn.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "style_dir = '../styles/'\n",
    "# style_background_name = args.background_style\n",
    "style_background_name = 'starry_night.jpg'\n",
    "# style_foreground_name = args.foreground_style\n",
    "style_foreground_name = None\n",
    "\n",
    "style_background_image = PIL.Image.open(os.path.join(style_dir, style_background_name))\n",
    "if style_foreground_name:\n",
    "    style_foreground_image = PIL.Image.open(os.path.join(style_dir, style_foreground_name))\n",
    "else:\n",
    "    style_foreground_image = None\n",
    "\n",
    "transfer_params = {\n",
    "    'content_image' : content_image,\n",
    "    'style_image' : style_background_image,\n",
    "    'content_mask': background_mask,\n",
    "    'image_size' : HEIGHT,\n",
    "    'content_layer' : 12,\n",
    "    'content_weight' : 1e-3,\n",
    "    'style_layers' : style_layers,\n",
    "    'style_weights' : (.02, .02, .02, .02, .02),\n",
    "    # 'tv_weight' : 1e-2,\n",
    "    'tv_weight' : 0,\n",
    "    'init_random' : False,\n",
    "    'mask_layer' : True,\n",
    "    'second_style_image' : style_foreground_image \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_img = style_transfer(**transfer_params)\n",
    "display_style_transfer(final_img, 'test.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
