{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from style_transfer import *\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import PIL\n",
    "import numpy as np\n",
    "from scipy.misc import imread\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import CocoStuffDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HEIGHT = WIDTH = 128\n",
    "val_dataset = CocoStuffDataSet(mode='val', supercategories=['animal'], height=HEIGHT, width=WIDTH, do_normalize=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "cnn = torchvision.models.vgg16(pretrained=True).features\n",
    "cnn.cuda()\n",
    "# cnn.type(dtype)\n",
    "# We don't want to train the model any further, so we don't want PyTorch to waste computation \n",
    "# computing gradients on parameters we're never going to update.\n",
    "for param in cnn.parameters():\n",
    "    param.requires_grad = False\n",
    "style_layers = (0, 5, 10, 17, 24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_style_weights(beta):\n",
    "    style_weights = np.array([100, 100, 10, 10, 1])\n",
    "    return [float(x) for x in beta*style_weights]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_savename(content_idx, style_background, style_foreground=None, ground_truth=True):\n",
    "    if ground_truth:\n",
    "        name = \"ground_truth_\"\n",
    "    else:\n",
    "        name = \"generated_\"\n",
    "    name += \"{}_{}\".format(content_idx, style_background.split('.')[0])\n",
    "    if style_foreground:\n",
    "        name += \"_and_{}\".format(style_foreground.split('.')[0])\n",
    "    name += \".png\"\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = {}\n",
    "\n",
    "def get_images_and_masks(load_folder, upsample=False):\n",
    "    \"\"\"\n",
    "    Return a list of (image, ground truth mask, generated mask)\n",
    "    for use in style transfer from input load_folder\n",
    "    Assumes directory structure:\n",
    "    code/\n",
    "        /saved_images_and_masks\n",
    "            /<load_folder>\n",
    "                /img.pk\n",
    "                /gt_mask.pk\n",
    "                /gen_mask.pk\n",
    "    \"\"\"\n",
    "    load_dir = os.path.join('./saved_images_and_masks', load_folder)\n",
    "    if load_dir in cache:\n",
    "        return cache[load_dir]\n",
    "    img = torch.load(os.path.join(load_dir, 'img.pk'))\n",
    "    img = PIL.Image.fromarray(np.uint8(img.numpy().transpose(1, 2, 0)*255.))\n",
    "    gt_mask = torch.load(os.path.join(load_dir, 'gt_mask.pk')).float()\n",
    "    gen_mask = torch.load(os.path.join(load_dir, 'gen_mask.pk')).float()\n",
    "    if upsample:\n",
    "        img = img.resize((2*HEIGHT, 2*WIDTH))\n",
    "        gt_mask = torch.from_numpy(gt_mask.numpy().repeat(2, axis=0).repeat(2, axis=1)).float()\n",
    "        gen_mask = torch.from_numpy(gen_mask.numpy().repeat(2, axis=0).repeat(2, axis=1)).float()\n",
    "    cache[load_dir] = (img, gt_mask, gen_mask)\n",
    "    return img, gt_mask, gen_mask    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1e-4\n",
    "beta = 1e3\n",
    "gamma = 1e-2\n",
    "savedir = './saved_style_transfers'\n",
    "if not os.path.exists(savedir):\n",
    "    os.makedirs(savedir)\n",
    "style_dir = '../styles/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backgrounds = ['the_scream.jpg', 'starry_night.jpg', 'tsunami.jpg']\n",
    "# foregrounds = ['guernica.jpg', 'guitar.jpg']\n",
    "\n",
    "backgrounds = ['starry_night.jpg']\n",
    "foregrounds = ['muse.jpg']\n",
    "\n",
    "background_images = [PIL.Image.open(os.path.join(style_dir, n)) for n in backgrounds]\n",
    "foreground_images = [PIL.Image.open(os.path.join(style_dir, n)) for n in foregrounds]\n",
    "# indices = [16, 27, 29, 37, 38, 39, 40, 42, 52, 55, 77, 514]\n",
    "indices = [77]\n",
    "for style_background_name in backgrounds:\n",
    "    for style_foreground_name in foregrounds:\n",
    "        style_background_image = PIL.Image.open(os.path.join(style_dir, style_background_name))\n",
    "        style_foreground_image = PIL.Image.open(os.path.join(style_dir, style_foreground_name))\n",
    "        for idx in indices :\n",
    "#             content_image, background_mask = get_image_from_dataset(val_dataset, idx)\n",
    "            content_image, background_mask, generated_background_mask = get_images_and_masks(str(idx), upsample=True) \n",
    "            savename = get_savename(idx, style_background_name, style_foreground_name, ground_truth=True)\n",
    "            savepath = os.path.join(savedir, savename)\n",
    "            transfer_params = {\n",
    "                'cnn' : cnn,\n",
    "                'content_image' : content_image,\n",
    "                'style_image' : style_background_image,\n",
    "                'content_mask': background_mask,\n",
    "                'image_size' : 2*HEIGHT,  # since we did upsampling\n",
    "                'style_size' : 512,\n",
    "                'content_layer' : 12,\n",
    "                'content_weight' : alpha,\n",
    "                'style_layers' : style_layers,\n",
    "                'style_weights' : get_style_weights(beta),\n",
    "                'tv_weight' : gamma,\n",
    "                'max_iters' : 3000,\n",
    "                'init_random' : False,\n",
    "                'mask_layer' : True,\n",
    "                'second_style_image' : style_foreground_image \n",
    "            }\n",
    "\n",
    "            final_img, final_loss, loss_list = style_transfer(**transfer_params)\n",
    "            display_style_transfer(final_img, savepath)\n",
    "            loss_list = loss_list[100:]\n",
    "            plt.plot(range(len(loss_list)), loss_list)\n",
    "            plt.show()\n",
    "            \n",
    "#             savename = get_savename(idx, style_background_name, style_foreground_name, ground_truth=False)\n",
    "#             savepath = os.path.join(savedir, savename)\n",
    "#             transfer_params['content_mask'] = generated_background_mask\n",
    "#             final_img, final_loss, loss_list = style_transfer(**transfer_params)\n",
    "#             display_style_transfer(final_img, savepath)\n",
    "#             loss_list = loss_list[100:]\n",
    "#             plt.plot(range(len(loss_list)), loss_list)\n",
    "#             plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
